{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Correspondence\n",
    "\n",
    "The notebooks in this folder replicate the experiments as performed for [CNNs on Surfaces using Rotation-Equivariant Features](https://doi.org/10.1145/3386569.3392437).\n",
    "\n",
    "The current notebook replicates the shape segmentation experiments from section `5.2 Comparisons`.\n",
    "\n",
    "## Imports\n",
    "We start by importing dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File reading and progressbar\n",
    "import os.path as osp\n",
    "import progressbar\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "# PyTorch and PyTorch Geometric dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn.inits import zeros\n",
    "from torch import autograd\n",
    "import os\n",
    "import trimesh as tm\n",
    "import vectorheat as vh\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "#tm.SHRECGTtoVertex()\n",
    "#tm.transferSHRECGT()\n",
    "#tm.splitsSHREC19()\n",
    "\n",
    "# Harmonic Surface Networks components\n",
    "# Layers\n",
    "from nn import (ECResNetBlock,LiftBlock, ParallelTransportPool, ParallelTransportUnpool,\n",
    "                TwinLoss, TwinEval, TangentPerceptron,\n",
    "                TangentLin, TangentNonLin, VectorDropout, ECHOBlock, ExtConvCplx)\n",
    "# Utility functions\n",
    "from utils.harmonic import magnitudes, norm2D\n",
    "# Rotated MNIST dataset\n",
    "from datasets import SHREC19PR\n",
    "# Transforms\n",
    "from transforms import (HarmonicPrecomp, VectorHeat, MultiscaleRadiusGraph, \n",
    "                        ScaleMask, FilterNeighbours, NormalizeArea, NormalizeAxes, Subsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "Next, we set a few parameters for our network. You can change these settings to experiment with different configurations of the network. Right now, the settings are set to the ones used in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Band-limit for extended convolution\n",
    "band_limit = 1\n",
    "\n",
    "# Number of rings in the radial profile\n",
    "n_corr_rings = 6\n",
    "\n",
    "# Number of conv rings\n",
    "n_conv_rings = 6\n",
    "\n",
    "# Learn radial offset for correlations\n",
    "offset = True;\n",
    "\n",
    "# Number of filters per block\n",
    "nf = [16, 32];\n",
    "\n",
    "n_des = 16;\n",
    "n_bins = 2;\n",
    "\n",
    "# Ratios used for pooling\n",
    "ratios=[1, 0.25]\n",
    "\n",
    "# Radius of convolution for each scale\n",
    "radii = [0.1, 0.2]\n",
    "\n",
    "# Output descriptor dimension\n",
    "desDim = 16;\n",
    "\n",
    "\n",
    "# Number of datasets per batch\n",
    "batch_size = 1\n",
    "\n",
    "bias = False;\n",
    "smooth = False;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "To get our dataset ready for training, we need to perform the following steps:\n",
    "1. Provide a path to load and store the dataset.\n",
    "2. Define transformations to be performed on the dataset:\n",
    "    - A transformation that computes a multi-scale radius graph and precomputes the logarithmic map.\n",
    "    - A transformation that masks the edges and vertices per scale and precomputes convolution components.\n",
    "3. Assign and load the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Provide a path to load and store the dataset.\n",
    "# Make sure that you have created a folder 'data' somewhere\n",
    "# and that you have downloaded and moved the raw datasets there\n",
    "path = osp.join('data', 'SHREC19PR')\n",
    "\n",
    "# 2. Define transformations to be performed on the dataset:\n",
    "# Transformation that computes a multi-scale radius graph and precomputes the logarithmic map.\n",
    "pre_transform = T.Compose((\n",
    "    #NormalizeArea(),\n",
    "    MultiscaleRadiusGraph(ratios, radii, loop=True, flow='target_to_source', sample_n=2048),\n",
    "    VectorHeat(max_lvl=len(ratios)-1),\n",
    "    Subsample(),\n",
    "))\n",
    "# Apply a random scale and random rotation to each shape\n",
    "#transform = None\n",
    "\n",
    "transform = T.Compose((\n",
    "    T.Center(),\n",
    "    T.RandomRotate(45, axis=0),\n",
    "    T.RandomRotate(45, axis=1),\n",
    "    T.RandomRotate(45, axis=2)\n",
    ")\n",
    ")\n",
    "\n",
    "# Transformations that masks the edges and vertices per scale and precomputes convolution components.\n",
    "scale0_transform = T.Compose((\n",
    "    ScaleMask(0),\n",
    "    FilterNeighbours(radii[0]),\n",
    "    HarmonicPrecomp(n_conv_rings, n_corr_rings, band_limit, max_r=radii[0]))\n",
    ")\n",
    "\n",
    "scale1_transform = T.Compose((\n",
    "    ScaleMask(1),\n",
    "    FilterNeighbours(radii[1]),\n",
    "    HarmonicPrecomp(n_conv_rings, n_corr_rings, band_limit, max_r=radii[1]))\n",
    ")\n",
    "\n",
    "\n",
    "# 3. Assign and load the datasets.\n",
    "trainS_dataset = SHREC19PR(path, 0, pre_transform=pre_transform, transform=transform)\n",
    "trainT_dataset = SHREC19PR(path, 1, pre_transform=pre_transform, transform=transform)\n",
    "\n",
    "testS_dataset = SHREC19PR(path, 2, pre_transform=pre_transform)\n",
    "testT_dataset = SHREC19PR(path, 3, pre_transform=pre_transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network architecture\n",
    "Now, we create the network architecture by creating a new `nn.Module`, `Net`. We first setup each layer in the `__init__` method of the `Net` class and define the steps to perform for each batch in the `forward` method. The following figure shows a schematic of the architecture we will be implementing:\n",
    "\n",
    "<img src=\"img/resnet_architecture.png\" width=\"800px\" />\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.lin0 = nn.Linear(3, nf[0])\n",
    "\n",
    "        self.lift = LiftBlock(3, nf[0], n_corr_rings, offset, MLP=False)\n",
    "                \n",
    "        self.resnet1 = ECResNetBlock(nf[0], nf[1], band_limit, n_conv_rings)\n",
    "                \n",
    "        self.resnet2 = ECResNetBlock(nf[1], nf[1], band_limit, n_conv_rings)\n",
    "        \n",
    "        self.resnet3 = ECResNetBlock(nf[1], nf[1], band_limit, n_conv_rings)\n",
    "        \n",
    "        self.resnet4 = ECResNetBlock(nf[1], nf[1], band_limit, n_conv_rings)\n",
    "\n",
    "        self.resnet5 = ECResNetBlock(nf[1], nf[1], band_limit, n_conv_rings)\n",
    "        \n",
    "        self.resnet6 = ECResNetBlock(nf[1], nf[1], band_limit, n_conv_rings)\n",
    "        \n",
    "        self.resnet7 = ECResNetBlock(nf[1], nf[1], band_limit, n_conv_rings)\n",
    "        \n",
    "        self.resnet8 = ECResNetBlock(nf[1], nf[0], band_limit, n_conv_rings, back=True)\n",
    "        \n",
    "        self.conv_final = ExtConvCplx(nf[0], nf[0], 1, n_conv_rings)\n",
    "\n",
    "        \n",
    "        #self.echo = ECHOBlock(nf[0], n_des, n_bins, desDim, band_limit, n_conv_rings, classify=False, mlpC=[128, 64])\n",
    "\n",
    "        #self.D = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.d = VectorDropout(p=0.0)\n",
    "\n",
    "        \n",
    "        self.res1 = TangentPerceptron(nf[0], nf[1])\n",
    "        \n",
    "        \n",
    "        self.res2 = TangentPerceptron(nf[1], nf[1])\n",
    "        \n",
    "        self.res3 = TangentPerceptron(nf[1], nf[1])\n",
    "                \n",
    "        self.res4 = TangentPerceptron(nf[1], nf[0])\n",
    "        \n",
    "        self.lin = TangentPerceptron(nf[1], nf[0])\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # Pool\n",
    "        self.pool = ParallelTransportPool(1, scale1_transform)\n",
    "        self.unpool = ParallelTransportUnpool(from_lvl=1)\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        \n",
    "        ###############\n",
    "        ### Level 1 ###\n",
    "        ###############\n",
    "        \n",
    "        data_scale0 = scale0_transform(data)\n",
    "\n",
    "        \n",
    "        \n",
    "        attr_grad = (data_scale0.edge_index, data_scale0.pcmp_gather)\n",
    "\n",
    "        attr_conv = (data_scale0.edge_index, data_scale0.pcmp_scatter, \n",
    "                      data_scale0.connection)    \n",
    "        \n",
    "        attr_echo = (data_scale0.edge_index, data_scale0.pcmp_scatter, \n",
    "                     data_scale0.pcmp_echo, data_scale0.connection)\n",
    " \n",
    "        x = data.pos\n",
    "\n",
    "        x1 = self.lift(x, *attr_grad)\n",
    "                                        \n",
    "        x = self.resnet1(x1, *attr_conv) \n",
    "        \n",
    "        x2 = self.resnet2(x, *attr_conv)  + self.res1(x1)\n",
    "                \n",
    "        x = self.resnet3(x2, *attr_conv)\n",
    "        \n",
    "        x3 = self.resnet4(x, *attr_conv) + self.res2(x2)\n",
    "        \n",
    "        x = self.resnet5(x, *attr_conv)\n",
    "        \n",
    "        x4 = self.resnet6(x, *attr_conv) + self.res3(x3)\n",
    "        \n",
    "        x = self.resnet7(x4, *attr_conv)\n",
    "        \n",
    "        x = self.resnet8(x, *attr_conv) + self.res4(x4)\n",
    "        \n",
    "       # x = self.echo(x, *attr_echo)\n",
    "        return norm2D(x)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Phew, we're through the hard part. Now, let's get to training. First, move the network to the GPU and setup an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to train on a GPU. It'll take a long time on a CPU\n",
    "device = torch.device('cuda')\n",
    "# Move the network to the GPU\n",
    "model = Net().to(device)\n",
    "statePath = '/home/tommy/Dropbox/specialMath/Harmonic/ECHONet/V7/plot/Figures/SHREC19PR/states/VFC_16_3'\n",
    "model.load_state_dict(torch.load(statePath))\n",
    "model = model.to(device)\n",
    "# Set up the ADAM optimizer with learning rate of 0.0076 (as used in H-Nets)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "decay = 0.975\n",
    "\n",
    "train_size = 80;\n",
    "test_size = 20;\n",
    "\n",
    "n_L_pairs = 512\n",
    "mu = 5\n",
    "ratio = 0.5\n",
    "twinL = TwinLoss(mu=mu)\n",
    "twinE = TwinEval(mu=mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def getNullPairs(pos_pairs, nSamples=2048):\n",
    "    pos_lin = pos_pairs[0] * nSamples + pos_pairs[1]\n",
    "    all_lin = torch.arange(nSamples * nSamples)\n",
    "    null_lin = torch.from_numpy(np.setdiff1d(all_lin.cpu().numpy(), pos_lin.cpu().numpy())).long()\n",
    "\n",
    "    npS = torch.remainder(null_lin, nSamples)\n",
    "    npT = torch.div(torch.sub(null_lin, npS), nSamples)\n",
    "    \n",
    "    return torch.cat( (npT[..., None], npS[..., None]), dim=1).long()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define a training and test function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, acc=0):\n",
    "    # Set model to 'train' mode\n",
    "    model.train()\n",
    "\n",
    "  \n",
    "    if epoch >= 25:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = 0.001;\n",
    "   \n",
    "            \n",
    "    # Sort out progress bar\n",
    "    n_data = trainS_dataset.__len__()\n",
    "    widgets = [progressbar.Percentage(), progressbar.Bar(), \n",
    "              progressbar.AdaptiveETA(), ' | Loss:', progressbar.Variable('loss'),]\n",
    "\n",
    "    bar = progressbar.ProgressBar(max_value=n_data, widgets=widgets)\n",
    "\n",
    "    order = torch.randperm(n_data).long()\n",
    "    \n",
    "    totalL = 0.0;\n",
    "    \n",
    "    for i in range(n_data):\n",
    "    # Move training data to the GPU and optimize parameters\n",
    "        #with autograd.detect_anomaly():\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        dataS = trainS_dataset.get(order[i])\n",
    "        dataT = trainT_dataset.get(order[i])\n",
    "\n",
    "        dataT.null_pairs = getNullPairs(dataT.pos_pairs, dataT.pos.size(0))\n",
    "        \n",
    "        FS = model(dataS.to(device))\n",
    "        FT = model(dataT.to(device))\n",
    "        \n",
    "\n",
    "        p_ = torch.randperm(dataT.pos_pairs.size(0))[:n_L_pairs];\n",
    "        n_ = torch.randperm(dataT.null_pairs.size(0))[:n_L_pairs]\n",
    "        \n",
    "        L = twinL(FS, FT, dataT.pos_pairs[p_, :], dataT.null_pairs[n_, :])\n",
    "                \n",
    "        totalL += L.item()\n",
    "        i = i + 1\n",
    "        bar.update(i, loss = (totalL / i) )\n",
    "        L.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train for 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    # Set model to 'evaluation' mode\n",
    "    model.eval()\n",
    "    \n",
    "    n_false_null = 0;\n",
    "    n_false_pos = 0;\n",
    "    \n",
    "    n_p = 0;\n",
    "    n_n = 0;\n",
    "        \n",
    "    n_test = testS_dataset.__len__();\n",
    "    for i in progressbar.progressbar(range(n_test)):\n",
    "        with torch.no_grad():\n",
    "            dataS = testS_dataset.get(i)\n",
    "            dataT = testT_dataset.get(i)\n",
    "            \n",
    "            dataT.null_pairs = getNullPairs(dataT.pos_pairs, dataT.pos.size(0))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "            FS = model(dataS.to(device))\n",
    "            FT = model(dataT.to(device))\n",
    "\n",
    "            nFP, nFN = twinE(FS, FT, dataT.pos_pairs, dataT.null_pairs)\n",
    "\n",
    "            n_false_pos += nFP\n",
    "            n_false_null += nFN\n",
    "\n",
    "            n_p += dataT.pos_pairs.size(0)\n",
    "            n_n += dataT.null_pairs.size(0)\n",
    "   \n",
    "\n",
    "    rateFP = n_false_pos / n_p\n",
    "    rateFN = n_false_null / n_n\n",
    "        \n",
    "    return rateFP, rateFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#statePath = '/home/tommy/Dropbox/specialMath/Harmonic/ECHONet/V7/plot/Figures/SHREC19PR/states/VFC_16_3'\n",
    "#model.load_state_dict(torch.load(statePath))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training, may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|#                                      |ETA:   0:02:12 | Loss:loss:   4.58"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a3ef36f1d03c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e12\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mrateFP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrateFN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-af11331ff9ee>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, acc)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotalL\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Environment/ECNet/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Environment/ECNet/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Start training, may take a while...')\n",
    "# Try with fewer epochs if you're in a timecrunch\n",
    "acc = 0;\n",
    "best=1e12;\n",
    "for epoch in range(45, 50):\n",
    "    train(epoch, acc)\n",
    "    if (epoch % 5) == 0 and epoch > 0:\n",
    "        rateFP, rateFN = test() \n",
    "        classE = rateFP + rateFN;\n",
    "        torch.save(model.state_dict(), statePath.format(epoch))\n",
    "        # if classE < best:\n",
    "            #best = classE\n",
    "            #torch.save(model.state_dict(), statePath.format(best))\n",
    "        print(\"Epoch {} - FP: {:06.4f}, FN: {:06.4f}, Err: {:06.4f} \".format(epoch, rateFP, rateFN, rateFP + rateFN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "## Plot\n",
    "#statePath = '/home/tommy/Dropbox/specialMath/Harmonic/ECHONet/V7/plot/Figures/SHREC19PR/temp/VFC_16_5'\n",
    "\n",
    "#torch.save(model.state_dict(), statePath)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.io import read_ply, read_off, read_obj\n",
    "import scipy as sp\n",
    "\n",
    "def curvePR(saveFile=None):\n",
    "    # Set model to 'evaluation' mode\n",
    "    model.eval()\n",
    "    \n",
    "    n_test = testS_dataset.__len__();\n",
    "    \n",
    "    nPoints = testS_dataset.get(0).pos.size(0)\n",
    "    \n",
    "    meanPR = torch.Tensor(2, nPoints).fill_(0)\n",
    "    \n",
    "    nCurves = 0;\n",
    "    nNAN = 0;\n",
    "    for i in progressbar.progressbar(range(n_test)):\n",
    "        with torch.no_grad():\n",
    "            dataS = testS_dataset.get(i)\n",
    "            dataT = testT_dataset.get(i)\n",
    "\n",
    "            FS = model(dataS.to(device))\n",
    "            FT = model(dataT.to(device))\n",
    "            \n",
    "            for l in range(nPoints):\n",
    "                \n",
    "                indST = torch.nonzero(dataT.pos_pairs[:, 1] == l).squeeze(1)\n",
    "                \n",
    "                if (indST.size(0) > 0):\n",
    "\n",
    "                    mST = dataT.pos_pairs[indST, 0]\n",
    "\n",
    "                    dST = torch.sum(torch.pow(torch.sub(FT, FS[l, None, :]), 2), dim=1)\n",
    "\n",
    "                    pr = torch.from_numpy(tm.computePR(dST.cpu().numpy(), mST.cpu().numpy()))\n",
    "                \n",
    "                    if torch.isnan(pr).any() == False:\n",
    "                        meanPR[...] = meanPR[...] + pr[...]\n",
    "                        nCurves = nCurves + 1\n",
    "                    else:\n",
    "                        nNAN = nNAN + 1;\n",
    "\n",
    "    meanPR = torch.div(meanPR, nCurves)\n",
    "    meanPR = meanPR.cpu().numpy()\n",
    "    \n",
    "    print('Num NaN = {}'.format(nNAN), flush=True)\n",
    "    \n",
    "    if saveFile is not None:\n",
    "        np.save(saveFile, meanPR)\n",
    "    \n",
    "    return meanPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.io import read_ply, read_off, read_obj\n",
    "import scipy as sp\n",
    "\n",
    "def curvePR2(saveFile=None, alpha = 0.05):\n",
    "    # Set model to 'evaluation' mode\n",
    "    model.eval()\n",
    "    \n",
    "    n_test = testS_dataset.__len__();\n",
    "    \n",
    "    nPoints = testS_dataset.get(0).pos.size(0)\n",
    "    \n",
    "    meanPR = torch.Tensor(2, nPoints).fill_(0)\n",
    "    \n",
    "    modelPath = '/home/tommy/Dropbox/specialMath/Harmonic/ECHONet/V7/data/SHREC19PR/raw/models_eval/{}.obj'\n",
    "\n",
    "    \n",
    "    \n",
    "    nCurves = 0;\n",
    "    nNAN = 0;\n",
    "    for i in progressbar.progressbar(range(n_test)):\n",
    "        with torch.no_grad():\n",
    "            dataS = testS_dataset.get(i)\n",
    "            dataT = testT_dataset.get(i)\n",
    "\n",
    "            gtInd = dataS.sample_idx[dataT.pos_pairs[:,1]]\n",
    "\n",
    "            FS = model(dataS.to(device))\n",
    "            FT = model(dataT.to(device))\n",
    "\n",
    "            ## Load original mesh + gt\n",
    "            dataS0 = read_obj(modelPath.format(dataS.name))\n",
    "            posS = dataS0.pos.cpu().numpy()     \n",
    "            facesS = dataS0.face.cpu().numpy().T\n",
    "            areaS = vh.surface_area(posS, facesS)   \n",
    "            posS = posS / np.sqrt(areaS)\n",
    "            \n",
    "            distMat = torch.from_numpy(tm.getAdjacentDist(posS, facesS, dataS.sample_idx.cpu().numpy()))\n",
    "            \n",
    "            for l in range(nPoints):\n",
    "                \n",
    "                local = torch.nonzero(distMat[l, :] <= alpha).squeeze(1)\n",
    "                \n",
    "                indST = torch.LongTensor();\n",
    "                \n",
    "                for k in range(local.size(0)):\n",
    "                    indST = torch.cat( (indST, torch.nonzero(dataT.pos_pairs[:, 1] == local[k]).squeeze(1).cpu()), dim=0);\n",
    "                \n",
    "                #indST = torch.nonzero(dataT.pos_pairs[:, 1] == l).squeeze(1)\n",
    "                \n",
    "                if (indST.size(0) > 0):\n",
    "\n",
    "                    mST = dataT.pos_pairs[indST, 0]\n",
    "\n",
    "                    dST = torch.sum(torch.pow(torch.sub(FT, FS[l, None, :]), 2), dim=1)\n",
    "\n",
    "                    pr = torch.from_numpy(tm.computePR(dST.cpu().numpy(), mST.cpu().numpy()))\n",
    "                \n",
    "                    if torch.isnan(pr).any() == False:\n",
    "                        meanPR[...] = meanPR[...] + pr[...]\n",
    "                        nCurves = nCurves + 1\n",
    "                    else:\n",
    "                        nNAN = nNAN + 1;\n",
    "\n",
    "    meanPR = torch.div(meanPR, nCurves)\n",
    "    meanPR = meanPR.cpu().numpy()\n",
    "    \n",
    "    print('Num NaN = {}'.format(nNAN), flush=True)\n",
    "    \n",
    "    if saveFile is not None:\n",
    "        np.save(saveFile, meanPR)\n",
    "    \n",
    "    return meanPR\n",
    "\n",
    "def allPR(savePath, alpha = 0.05):\n",
    "    # Set model to 'evaluation' mode\n",
    "    model.eval()\n",
    "    \n",
    "    n_test = testS_dataset.__len__();\n",
    "    \n",
    "    nPoints = testS_dataset.get(0).pos.size(0)\n",
    "    \n",
    "    meanPR = torch.Tensor(2, nPoints).fill_(0)\n",
    "    \n",
    "    modelPath = '/home/tommy/Dropbox/specialMath/Harmonic/ECHONet/V7/data/SHREC19PR/raw/models_eval/{}.obj'\n",
    "\n",
    "    \n",
    "    \n",
    "    nCurves = 0;\n",
    "    nNAN = 0;\n",
    "    for i in progressbar.progressbar(range(n_test)):\n",
    "        with torch.no_grad():\n",
    "            dataS = testS_dataset.get(i)\n",
    "            dataT = testT_dataset.get(i)\n",
    "\n",
    "            gtInd = dataS.sample_idx[dataT.pos_pairs[:,1]]\n",
    "\n",
    "            FS = model(dataS.to(device))\n",
    "            FT = model(dataT.to(device))\n",
    "\n",
    "            ## Load original mesh + gt\n",
    "            dataS0 = read_obj(modelPath.format(dataS.name))\n",
    "            posS = dataS0.pos.cpu().numpy()     \n",
    "            facesS = dataS0.face.cpu().numpy().T\n",
    "            areaS = vh.surface_area(posS, facesS)   \n",
    "            posS = posS / np.sqrt(areaS)\n",
    "            \n",
    "            distMat = torch.from_numpy(tm.getAdjacentDist(posS, facesS, dataS.sample_idx.cpu().numpy()))\n",
    "            \n",
    "            prMat = torch.FloatTensor(nPoints, 2, nPoints).fill_(0)\n",
    "            \n",
    "            for l in range(nPoints):\n",
    "                \n",
    "                local = torch.nonzero(distMat[l, :] <= alpha).squeeze(1)\n",
    "                \n",
    "                indST = torch.LongTensor();\n",
    "                \n",
    "                for k in range(local.size(0)):\n",
    "                    indST = torch.cat( (indST, torch.nonzero(dataT.pos_pairs[:, 1] == local[k]).squeeze(1).cpu()), dim=0);\n",
    "                \n",
    "                #indST = torch.nonzero(dataT.pos_pairs[:, 1] == l).squeeze(1)\n",
    "                \n",
    "                if (indST.size(0) > 0):\n",
    "\n",
    "                    mST = dataT.pos_pairs[indST, 0]\n",
    "\n",
    "                    dST = torch.sum(torch.pow(torch.sub(FT, FS[l, None, :]), 2), dim=1)\n",
    "\n",
    "                    pr = torch.from_numpy(tm.computePR(dST.cpu().numpy(), mST.cpu().numpy()))\n",
    "                \n",
    "                    prMat[l, :, :] = torch.from_numpy(pr).float();\n",
    "                    \n",
    "                    meanPR[...] = meanPR[...] + pr[...]\n",
    "                    nCurves = nCurves + 1\n",
    "                else:\n",
    "                    prMat[l, 0, 1] = -1;\n",
    "\n",
    "            saveFile = savePath + '{0}.{1}.pr'.format(dataS.name, dataT.name)\n",
    "            np.save(saveFile, prMat.cpu().numpy())\n",
    "            \n",
    "    meanPR = torch.div(meanPR, nCurves)\n",
    "    \n",
    "    print(\"zeroP = \", meanPR[0, 0], flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.io import read_ply, read_off, read_obj\n",
    "\n",
    "def normalizedError(saveFile=None):\n",
    "    # Set model to 'evaluation' mode\n",
    "    model.eval()\n",
    "    \n",
    "    modelPath = '/home/tommy/Dropbox/specialMath/Harmonic/ECHONet/V7/data/SHREC19PR/raw/models_eval/{}.obj'\n",
    "    gtPath = '/home/tommy/Dropbox/specialMath/Harmonic/ECHONet/V7/data/SHREC19PR/raw/gt/{0}.{1}.gt.txt'\n",
    "    \n",
    "    n_test = testS_dataset.__len__();\n",
    "    for i in progressbar.progressbar(range(n_test)):\n",
    "        with torch.no_grad():\n",
    "            dataS = testS_dataset.get(i)\n",
    "            dataT = testT_dataset.get(i)\n",
    "            \n",
    "            gtInd = dataS.sample_idx[dataT.pos_pairs[:,1]]\n",
    "\n",
    "            FS = model(dataS.to(device))\n",
    "            FT = model(dataT.to(device))\n",
    "\n",
    "            ## Load original mesh + gt\n",
    "            dataS0 = read_obj(modelPath.format(dataS.name))\n",
    "            posS = dataS0.pos.cpu().numpy()     \n",
    "            facesS = dataS0.face.cpu().numpy().T\n",
    "            areaS = vh.surface_area(posS, facesS)   \n",
    "            posS = posS / np.sqrt(areaS)\n",
    "\n",
    "            ### Get indices of nearest descriptors\n",
    "            nearestInd = torch.from_numpy(tm.getNearestDes(FS.cpu().numpy(), FT.cpu().numpy(), \n",
    "                                                            dataS.sample_idx[:,  None].cpu().numpy()).astype(int)).long()\n",
    "\n",
    "\n",
    "            compInd = torch.cat( (nearestInd, gtInd[..., None]), dim=1)\n",
    "\n",
    "            # Compute geodesic error\n",
    "            error = tm.getGeoError(posS, facesS, compInd.cpu().numpy()).squeeze()\n",
    "\n",
    "            if i == 0:\n",
    "                E = torch.from_numpy(error).float()\n",
    "            else:\n",
    "                E = torch.cat((E, torch.from_numpy(error).float()), dim=0)   \n",
    "\n",
    "    E, _ = torch.sort(E)\n",
    "\n",
    "    E = E.cpu().numpy()\n",
    "    \n",
    "    if saveFile is not None:\n",
    "        np.save(saveFile, E)\n",
    "    \n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "savePath = '/home/tommy/Dropbox/specialMath/Harmonic/ECHONet/V7/plot/SHREC19PR/'\n",
    "\n",
    "ID = 'VFC_16_pr_3_2'\n",
    "\n",
    "rawFile = savePath + ID + '_raw.npy'\n",
    "\n",
    "plotFile = savePath + ID + '_plot.txt'\n",
    "'''\n",
    "\n",
    "savePath = '/home/tommy/Dropbox/specialMath/Harmonic/ECHONet/V7/plot/Figures/SHREC19PR/hitRate/FC/3/'\n",
    "allPR(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#statePath = '/home/tommy/Dropbox/specialMath/Harmonic/ECHONet/V7/plot/SHREC19PR/states/VFC_16_3_Final'\n",
    "#model.load_state_dict(torch.load(statePath))\n",
    "\n",
    "#prCurve = curvePR2(rawFile);\n",
    "#E = normalizedError(rawFile);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "prCurve = np.load(rawFile)\n",
    "\n",
    "nSamples = 200;\n",
    "\n",
    "x0 = prCurve[1, 0]\n",
    "\n",
    "#print(prCurve[0, :5])\n",
    "\n",
    "xVal = np.arange(0, nSamples+1) / nSamples;\n",
    "\n",
    "xVal = (1 - x0)*xVal + x0;\n",
    "\n",
    "\n",
    "fPR = sp.interpolate.interp1d(prCurve[1, :], prCurve[0, :])\n",
    "\n",
    "plotPR = fPR(xVal)\n",
    "\n",
    "np.savetxt(plotFile, plotPR, fmt='%f')\n",
    "'''\n",
    "\n",
    "'''\n",
    "E = np.load(rawFile)\n",
    "nESamples = 100;\n",
    "maxE = 1.0;\n",
    "step = maxE / nESamples\n",
    "epsE = step / 100;\n",
    "\n",
    "E = torch.from_numpy(E)\n",
    "\n",
    "nPairs = E.size(0)\n",
    "\n",
    "\n",
    "plot = torch.Tensor(nESamples + 1).fill_(0)\n",
    "\n",
    "for l in range(nESamples+1):\n",
    "    \n",
    "    if l == 0:\n",
    "        thresh = epsE;\n",
    "    else:   \n",
    "        thresh = step*l;\n",
    "        \n",
    "    nMatches = torch.nonzero(E <= thresh).size(0)\n",
    "    \n",
    "    plot[l] = nMatches / nPairs;\n",
    "\n",
    "plotError = plot.cpu().numpy();\n",
    "\n",
    "np.savetxt(plotFile, plotError, fmt='%f')\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ACSpath = '/home/tommy/Dropbox/specialMath/Harmonic/ECHONet/ACSCNN/SHREC19/2/';\n",
    "\n",
    "ACSsamples = osp.join(osp.join(ACSpath, 'samples'), '{0}.{1}.npy')\n",
    "ACSmatches = osp.join(osp.join(ACSpath, 'matches'), '{0}.{1}.npy')\n",
    "ACStestpairs = osp.join(ACSpath, 'test_pairs.npy')\n",
    "ACStrainpairs = osp.join(ACSpath, 'train_pairs.npy')\n",
    "\n",
    "n_train = trainS_dataset.__len__()\n",
    "n_test = testS_dataset.__len__();\n",
    "\n",
    "test_pairs_S = [];\n",
    "test_pairs_T = [];\n",
    "        \n",
    "train_pairs_S =[];\n",
    "train_pairs_T =[];\n",
    "\n",
    "    \n",
    "for i in range(n_train):\n",
    "\n",
    "    dataS = trainS_dataset.get(i)\n",
    "    dataT = trainT_dataset.get(i)\n",
    "    \n",
    "    sName = dataS.name;\n",
    "    tName = dataT.name;\n",
    "        \n",
    "    sID = sName[sName[:len(sName)-1].rfind('0')+1:]\n",
    "    tID = tName[tName[:len(tName)-1].rfind('0')+1:]\n",
    "    \n",
    "    sID = int(sID)\n",
    "    tID = int(tID)\n",
    "\n",
    "    samples = torch.cat((dataT.sample_idx[..., None], dataS.sample_idx[..., None]), dim=1).cpu().numpy().astype(int)\n",
    "\n",
    "    p_matches = dataT.pos_pairs.cpu().numpy().astype(int);\n",
    "\n",
    "    np.save(ACSsamples.format(sID, tID), samples)\n",
    "\n",
    "    np.save(ACSmatches.format(sID, tID), p_matches)\n",
    "\n",
    "    train_pairs_S.append(sID);\n",
    "    train_pairs_T.append(tID);\n",
    "    \n",
    "    \n",
    "for i in range(n_test):\n",
    "\n",
    "    dataS = testS_dataset.get(i)\n",
    "    dataT = testT_dataset.get(i)\n",
    "    \n",
    "    sName = dataS.name;\n",
    "    tName = dataT.name;\n",
    "    \n",
    "    sID = sName[sName[:len(sName)-1].rfind('0')+1:]\n",
    "    tID = tName[tName[:len(tName)-1].rfind('0')+1:]\n",
    "    \n",
    "    sID = int(sID)\n",
    "    tID = int(tID)\n",
    "    samples = torch.cat((dataT.sample_idx[..., None], dataS.sample_idx[..., None]), dim=1).cpu().numpy().astype(int)\n",
    "\n",
    "    p_matches = dataT.pos_pairs.cpu().numpy().astype(int);\n",
    "\n",
    "    np.save(ACSsamples.format(sID, tID), samples)\n",
    "\n",
    "    np.save(ACSmatches.format(sID, tID), p_matches)\n",
    "\n",
    "    test_pairs_S.append(sID);\n",
    "    test_pairs_T.append(tID);\n",
    "    \n",
    "\n",
    "train_p_S = torch.tensor(train_pairs_S).long()\n",
    "train_p_T = torch.tensor(train_pairs_T).long()\n",
    "test_p_S = torch.tensor(test_pairs_S).long()\n",
    "test_p_T = torch.tensor(test_pairs_T).long()\n",
    "\n",
    "train_p = torch.cat( (train_p_S[..., None], train_p_T[..., None]), dim=1).cpu().numpy().astype(int)\n",
    "test_p = torch.cat( (test_p_S[..., None], test_p_T[..., None]), dim=1).cpu().numpy().astype(int)\n",
    "\n",
    "np.save(ACStestpairs, test_p);\n",
    "np.save(ACStrainpairs, train_p);\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
