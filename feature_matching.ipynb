{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Matching\n",
    "\n",
    "### This notebook replicates the feature matching experiments  in section 6.5 of \"Field Convolutions for Surface CNNs\" (Mitchel et al. 2021)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File reading and progressbar\n",
    "import os\n",
    "import os.path as osp\n",
    "import progressbar\n",
    "\n",
    "# Numpy\n",
    "import numpy as np\n",
    "\n",
    "# Random\n",
    "import random\n",
    "\n",
    "# PyTorch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import autograd\n",
    "\n",
    "# PyTorch Geometric - used for data loading/processing\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "# Field Convolution modules\n",
    "from nn import FCResNetBlock, LiftBlock, TangentPerceptron, TwinLoss, TwinEval\n",
    "\n",
    "# Feature magnitudes\n",
    "from utils.field import softAbs\n",
    "\n",
    "# Transforms\n",
    "from transforms import FCPrecomp, computeLogXPort, SupportGraph\n",
    "\n",
    "# Load the Isometric & Non-Isometric Shape Correspondence dataset (Dyke et al., 2019)\n",
    "from datasets import SHREC19\n",
    "\n",
    "# Clear your cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Band-limit for field convolution filters\n",
    "band_limit = 1\n",
    "\n",
    "# Number of radial samples\n",
    "n_rings = 6\n",
    "\n",
    "# Filter type (see /nn/field_conv.py)\n",
    "ftype = 1\n",
    "\n",
    "# Number of channels in the network\n",
    "nf = 32\n",
    "\n",
    "# Filter support radius\n",
    "epsilon = 0.1;\n",
    "\n",
    "# Number of sample points on meshes\n",
    "n_samples = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where dataset is stored\n",
    "# The path to the .zip file containing the data should be\n",
    "# /data/SHREC19/raw/SHREC19.zip\n",
    "\n",
    "path = osp.join('data', 'SHREC19')\n",
    "\n",
    "# Pre-processing operations\n",
    "# Sample points on meshes and compute convolution support edges\n",
    "# Compute logarithm maps + parallel transport\n",
    "pre_transform = T.Compose((\n",
    "    SupportGraph(epsilon=epsilon, sample_n=n_samples),\n",
    "    computeLogXPort()\n",
    "))\n",
    "\n",
    "# Apply a random rotation every time a shape is drawn from the dataloader\n",
    "transform = T.Compose((\n",
    "    T.Center(),\n",
    "    T.RandomRotate(45, axis=0),\n",
    "    T.RandomRotate(45, axis=1),\n",
    "    T.RandomRotate(45, axis=2))\n",
    ")\n",
    "\n",
    "# Load test and train splits (sorce shapes + target shapes)\n",
    "trainS_dataset = SHREC19(path, 0, n_samples=n_samples, pre_transform=pre_transform, transform=transform)\n",
    "trainT_dataset = SHREC19(path, 1, n_samples=n_samples, pre_transform=pre_transform, transform=transform)\n",
    "\n",
    "testS_dataset = SHREC19(path, 2, n_samples=n_samples, pre_transform=pre_transform)\n",
    "testT_dataset = SHREC19(path, 3, n_samples=n_samples, pre_transform=pre_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCNet\n",
    "##### Eight FCResNet blocks, followed by a linear layer to map network features a 16-dimensional descriptor.  A learnable gradient-like operation is used to lift scalar features to isometry-equivariant tangent vector fields at the beginning of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Organizes edge data at run time to expidte convolutions\n",
    "organizeEdges = FCPrecomp(band_limit=band_limit, n_rings=n_rings, epsilon=epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        ## Learned 'gradient', lifting scalar features to tangent vector features\n",
    "        ## at the beginning of the network\n",
    "        \n",
    "        self.lift = LiftBlock(3, 16, n_rings=n_rings, ftype=ftype)\n",
    "        \n",
    "        ## FCNet - eight FCResNet Blocks\n",
    "        self.resnet1 = FCResNetBlock(16, nf, band_limit=band_limit, \n",
    "                                     n_rings=n_rings, ftype=ftype)\n",
    "                \n",
    "        self.resnet2 = FCResNetBlock(nf, nf, band_limit=band_limit,\n",
    "                                     n_rings=n_rings, ftype=ftype)\n",
    "        \n",
    "        self.resnet3 = FCResNetBlock(nf, nf, band_limit=band_limit,\n",
    "                                     n_rings=n_rings, ftype=ftype)\n",
    "        \n",
    "        self.resnet4 = FCResNetBlock(nf, nf, band_limit=band_limit,\n",
    "                                     n_rings=n_rings, ftype=ftype)\n",
    "\n",
    "        self.resnet5 = FCResNetBlock(nf, nf, band_limit=band_limit,\n",
    "                                     n_rings=n_rings, ftype=ftype)\n",
    "        \n",
    "        self.resnet6 = FCResNetBlock(nf, nf, band_limit=band_limit,\n",
    "                                     n_rings=n_rings, ftype=ftype)\n",
    "        \n",
    "        self.resnet7 = FCResNetBlock(nf, nf, band_limit=band_limit,\n",
    "                                     n_rings=n_rings, ftype=ftype)\n",
    "        \n",
    "        self.resnet8 = FCResNetBlock(nf, nf, band_limit=band_limit,\n",
    "                                     n_rings=n_rings, ftype=ftype)\n",
    "\n",
    "\n",
    "        \n",
    "        ## 'Meta' residual connections (in addition to those alredy inside the FCResNet blocks)\n",
    "        self.res1 = TangentPerceptron(16, nf)\n",
    "        \n",
    "        self.res2 = TangentPerceptron(nf, nf)\n",
    "        \n",
    "        self.res3 = TangentPerceptron(nf, nf)\n",
    "        \n",
    "        self.res4 = TangentPerceptron(nf, nf)\n",
    "        \n",
    "        ## Linear layer mapping features to 16-dimensional descriptors\n",
    "        self.out = TangentPerceptron(nf, 16)\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        \n",
    "        ##########################\n",
    "        ### Organize edge data ###\n",
    "        ##########################\n",
    "        supp_edges, supp_sten, _, _ = organizeEdges(data)\n",
    "        \n",
    "        attr_lift = (supp_edges, supp_sten[..., band_limit:(band_limit+2)])\n",
    "        attr_conv = (supp_edges, supp_sten)\n",
    "        \n",
    "        \n",
    "        #############################################\n",
    "        ### Lift scalar features to vector fields ###\n",
    "        #############################################\n",
    "        \n",
    "        x = data.pos[data.sample_idx, :]\n",
    "        \n",
    "        x1 = self.lift(x, *attr_lift)\n",
    "\n",
    "        ##########################\n",
    "        ### Field Convolutions ###\n",
    "        ##########################\n",
    "        \n",
    "        x = self.resnet1(x1, *attr_conv) \n",
    "        \n",
    "        x2 = self.resnet2(x, *attr_conv) + self.res1(x1)\n",
    "        \n",
    "        x = self.resnet3(x2, *attr_conv)\n",
    "        \n",
    "        x3 = self.resnet4(x, *attr_conv) + self.res2(x2)\n",
    "        \n",
    "        x = self.resnet5(x3, *attr_conv)\n",
    "        \n",
    "        x4 = self.resnet6(x, *attr_conv) + self.res3(x3)\n",
    "        \n",
    "        x = self.resnet7(x4, *attr_conv)\n",
    "        \n",
    "        x = self.resnet8(x, *attr_conv) + self.res4(x4)\n",
    "        \n",
    "        #########################################\n",
    "        ### Map features to output descriptor ###\n",
    "        #########################################\n",
    "        \n",
    "        return softAbs(self.out(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on the GPU\n",
    "device = torch.device('cuda')\n",
    "model = Net().to(device)\n",
    "\n",
    "# ADAM Optimizer, lr = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "## Twin loss \n",
    "loss = TwinLoss();\n",
    "ev = TwinEval()\n",
    "\n",
    "# Randomly sample 512 pairs of corresponding and non-corresponding points\n",
    "n_pairs = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Corresponding pairs are computed during data pre-processing\n",
    "## To get non-corresponding pairs, we consider the complement at run time\n",
    "def getNullPairs(pos_pairs, nSamples=n_samples):\n",
    "    pos_lin = pos_pairs[0] * nSamples + pos_pairs[1]\n",
    "    all_lin = torch.arange(nSamples * nSamples)\n",
    "    null_lin = torch.from_numpy(np.setdiff1d(all_lin.cpu().numpy(), pos_lin.cpu().numpy())).long()\n",
    "\n",
    "    npS = torch.remainder(null_lin, nSamples)\n",
    "    npT = torch.div(torch.sub(null_lin, npS), nSamples)\n",
    "    \n",
    "    return torch.cat( (npT[..., None], npS[..., None]), dim=1).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Twin network: the same network computes features on the source and target mesh\n",
    "## and the loss function compares features at corresponding + non-corresponding points\n",
    "def train(batch_step=1):\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    # Sort out progress bar, displays average loss over last 15 samples\n",
    "    wW = 15;\n",
    "    window = torch.FloatTensor(wW).fill_(0)\n",
    "    \n",
    "    n_data = trainS_dataset.__len__()\n",
    "    widgets = [progressbar.Percentage(), progressbar.Bar(), \n",
    "              progressbar.AdaptiveETA(), ' | ', progressbar.Variable('Loss'),]\n",
    "\n",
    "    bar = progressbar.ProgressBar(max_value=n_data, widgets=widgets)\n",
    "\n",
    "    # Manually shuffle data\n",
    "    order = torch.randperm(n_data).long()\n",
    "   \n",
    "    ## Zero-out\n",
    "    optimizer.zero_grad() \n",
    "\n",
    "    for i in range(n_data):\n",
    "        \n",
    "        # Load source and target meshes\n",
    "        dataS = trainS_dataset.get(order[i])\n",
    "        dataT = trainT_dataset.get(order[i])\n",
    "\n",
    "        # Get non-corresponding pairs\n",
    "        dataT.null_pairs = getNullPairs(dataT.pos_pairs)\n",
    "        \n",
    "        # Compute feature descriptors on source and target models\n",
    "        FS = model(dataS.to(device))\n",
    "        FT = model(dataT.to(device))\n",
    "        \n",
    "        # Randomly sample 512 pairs of corresponding and non-corresponding points each\n",
    "        p_ = torch.randperm(dataT.pos_pairs.size(0))[:n_pairs];\n",
    "        n_ = torch.randperm(dataT.null_pairs.size(0))[:n_pairs]\n",
    "    \n",
    "        # Compute loss\n",
    "        L = loss(FS, FT, dataT.pos_pairs[p_, :], dataT.null_pairs[n_, :])\n",
    " \n",
    "        # Update progress bar\n",
    "        if (i < wW):\n",
    "            window[i] = L.item()\n",
    "            wAvg = torch.mean(window[:i])\n",
    "        else:\n",
    "            window = torch.cat((window[1:], torch.tensor([L.item() * batch_step])), dim=0)\n",
    "            wAvg = torch.mean(window)\n",
    "        \n",
    "        bar.update(i+1, Loss=wAvg)\n",
    "        \n",
    "        # Update loss\n",
    "        L = L / batch_step\n",
    "        L.backward()\n",
    "        \n",
    "        if (i % batch_step == 0 or i == n_data):\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the percentage of false positive and false negative matches on the test dataset\n",
    "## You want both to decay for a good PR curve\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    \n",
    "    n_false_null = 0;\n",
    "    n_false_pos = 0;\n",
    "    \n",
    "    n_p = 0;\n",
    "    n_n = 0;\n",
    "        \n",
    "    n_test = testS_dataset.__len__();\n",
    "    for i in progressbar.progressbar(range(n_test)):\n",
    "        with torch.no_grad():\n",
    "            dataS = testS_dataset.get(i)\n",
    "            dataT = testT_dataset.get(i)\n",
    "            \n",
    "            dataT.null_pairs = getNullPairs(dataT.pos_pairs)\n",
    "\n",
    "\n",
    "            FS = model(dataS.to(device))\n",
    "            FT = model(dataT.to(device))\n",
    "\n",
    "            nFP, nFN = ev(FS, FT, dataT.pos_pairs, dataT.null_pairs)\n",
    "\n",
    "            n_false_pos += nFP\n",
    "            n_false_null += nFN\n",
    "\n",
    "            n_p += dataT.pos_pairs.size(0)\n",
    "            n_n += dataT.null_pairs.size(0)\n",
    "   \n",
    "\n",
    "    rateFP = n_false_pos / n_p\n",
    "    rateFN = n_false_null / n_n\n",
    "        \n",
    "    return rateFP, rateFN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, then test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Training...')\n",
    "for epoch in range(80):\n",
    "    \n",
    "    print('Epoch {}'.format(epoch))\n",
    "    train()\n",
    "    \n",
    "    ## Decay the learning rate after a while\n",
    "    if (epoch == 40):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = 0.001\n",
    "            \n",
    "rateFP, rateFN = test() \n",
    "print(\"Test split: FP: {:06.4f}, FN: {:06.4f}, Err: {:06.4f}\".format(rateFP, rateFN, rateFP + rateFN))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
