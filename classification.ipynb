{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "### This notebook replicates the shape classification experiments in section 6.2 of \"Field Convolutions for Surface CNNs\" (Mitchel et al. 2021)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File reading and progressbar\n",
    "import os\n",
    "import os.path as osp\n",
    "import progressbar\n",
    "\n",
    "# Numpy\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import autograd\n",
    "\n",
    "# PyTorch Geometric - used for data loading/processing\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "# Field Convolution modules\n",
    "from nn import FCResNetBlock, LiftBlock, FieldConv\n",
    "\n",
    "# Feature magnitudes\n",
    "from utils.field import softAbs\n",
    "\n",
    "# Transforms\n",
    "from transforms import FCPrecomp, computeLogXPort, SupportGraph, NormalizeArea, NormalizeAxes\n",
    "\n",
    "# Load the SHREC '11 shape classification dataset \n",
    "from datasets import SHREC11\n",
    "\n",
    "# Clear your cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Band-limit for field convolution filters\n",
    "band_limit = 2\n",
    "\n",
    "# Number of radial samples\n",
    "n_rings = 6\n",
    "\n",
    "# Filter type (see /nn/field_conv.py)\n",
    "ftype = 1\n",
    "\n",
    "# Number of channels in the network\n",
    "nf = 32\n",
    "\n",
    "# Filter support radius\n",
    "epsilon = 0.2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where dataset is stored\n",
    "# The path to the .zip file containing the data should be\n",
    "# /data/SHREC11/raw/SHREC11.zip\n",
    "path = osp.join('data', 'SHREC11')\n",
    "\n",
    "# Pre-processing operations\n",
    "# Normalize meshes to have unit surface area\n",
    "# Sample points on meshes and compute convolution support edges\n",
    "# Compute logarithm maps + parallel transport\n",
    "pre_transform = T.Compose((\n",
    "    NormalizeArea(),\n",
    "    SupportGraph(epsilon=epsilon),\n",
    "    computeLogXPort()\n",
    "))\n",
    "\n",
    "\n",
    "# Apply a random rotation and scale every time a shape is drawn from the dataloader\n",
    "transform = T.Compose((\n",
    "    T.RandomScale((0.85, 1.15)),\n",
    "    T.RandomRotate(45, axis=0),\n",
    "    T.RandomRotate(45, axis=1),\n",
    "    T.RandomRotate(45, axis=2))\n",
    ")\n",
    "\n",
    "\n",
    "# Load test and train splits\n",
    "test_dataset = SHREC11(path, False, pre_transform=pre_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "train_dataset = SHREC11(path, True, pre_transform=pre_transform, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "n_classes = train_dataset.num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCNet\n",
    "\n",
    "##### Two FCResNet blocks, followed by a field convolution to map network features to class predictions.  A learnable gradient-like operation is used to lift scalar features to isometry-equivariant tangent vector fields at the beginning of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Organizes edge data at run time to expidte convolutions\n",
    "organizeEdges = FCPrecomp(band_limit=band_limit, n_rings=n_rings, epsilon=epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        ## Learned 'gradient', lifting scalar features to tangent vector features\n",
    "        ## at the beginning of the network\n",
    "        self.lift = LiftBlock(3, nf, n_rings=n_rings, ftype=ftype)\n",
    "        \n",
    "        ## FCNet - two FCResNet Blocks, followed by a field convolution \n",
    "\n",
    "        self.resnet1 = FCResNetBlock(nf, nf, band_limit=band_limit, \n",
    "                                     n_rings=n_rings, ftype=ftype)\n",
    "        \n",
    "        self.resnet2 = FCResNetBlock(nf, nf, band_limit=band_limit, \n",
    "                                     n_rings=n_rings, ftype=ftype)\n",
    "                \n",
    "        \n",
    "        self.conv_out = FieldConv(nf, n_classes, band_limit=band_limit,\n",
    "                                 n_rings=n_rings, ftype=ftype)\n",
    "        \n",
    "        ## Bias applied to output prediction\n",
    "        self.bias = nn.Parameter(torch.Tensor(1, n_classes))\n",
    "        torch.nn.init.zeros_(self.bias)\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        \n",
    "        ##########################\n",
    "        ### Organize edge data ###\n",
    "        ##########################\n",
    "        supp_edges, supp_sten, _, _ = organizeEdges(data)\n",
    "        \n",
    "        attr_lift = (supp_edges, supp_sten[..., band_limit:(band_limit+2)])\n",
    "        attr_conv = (supp_edges, supp_sten)\n",
    "        \n",
    "        \n",
    "        #############################################\n",
    "        ### Lift scalar features to vector fields ###\n",
    "        #############################################\n",
    "        \n",
    "        x = data.pos[data.sample_idx, :]\n",
    "        \n",
    "        x = self.lift(x, *attr_conv)\n",
    "        \n",
    "        ##########################\n",
    "        ### Field Convolutions ###\n",
    "        ##########################\n",
    "        \n",
    "        x = self.resnet1(x, *attr_conv) \n",
    "        \n",
    "        x = self.resnet2(x, *attr_conv)\n",
    "        \n",
    "        ################################\n",
    "        ### Mean pool for prediction ###\n",
    "        ################################\n",
    "        \n",
    "        x = self.conv_out(x, *attr_conv)\n",
    "        \n",
    "        x = torch.mean(softAbs(x), dim=0, keepdim=True)\n",
    "        \n",
    "        return x + self.bias;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on the GPU\n",
    "device = torch.device('cuda')\n",
    "model = Net().to(device)\n",
    "\n",
    "# ADAM Optimizer, lr = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "## Cross Entropy Loss\n",
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training function\n",
    "## Optional batch_step parameter for gradient accumulation (not used in the paper)\n",
    "def train(batch_step=1):\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    # Sort out progress bar, displays average loss over last 10 samples\n",
    "    wW = 10;\n",
    "    window = torch.FloatTensor(wW).fill_(0)\n",
    "    \n",
    "    n_data = train_loader.__len__()\n",
    "    widgets = [progressbar.Percentage(), progressbar.Bar(), \n",
    "              progressbar.AdaptiveETA(), ' | ', progressbar.Variable('Loss'),]\n",
    "\n",
    "    bar = progressbar.ProgressBar(max_value=n_data, widgets=widgets)\n",
    "\n",
    "    \n",
    "    ## Zero-out\n",
    "    optimizer.zero_grad() \n",
    "\n",
    "    i = 0;\n",
    "    for data in train_loader:\n",
    "            \n",
    "        pred = model(data.to(device))\n",
    "\n",
    "        L = loss(pred, data.y.to(device))\n",
    "\n",
    "        if (i < wW):\n",
    "            window[i] = L.item()\n",
    "            wAvg = torch.mean(window[:i])\n",
    "        else:\n",
    "            window = torch.cat((window[1:], torch.tensor([L.item()])), dim=0)\n",
    "            wAvg = torch.mean(window)\n",
    "\n",
    "        # Update progress bar\n",
    "        i = i + 1\n",
    "        bar.update(i, Loss = torch.mean(window[:i]))\n",
    "        \n",
    "        ## Update loss\n",
    "        L = L / batch_step;\n",
    "        L.backward()\n",
    "\n",
    "        if ( i % batch_step == 0 or i == n_data ):\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute classification accuracy on test set   \n",
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total_num = 0\n",
    "    for i, data in enumerate(test_loader):\n",
    "        pred = model(data.to(device)).max(1)[1]\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "        total_num += 1\n",
    "    return correct / total_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, then test\n",
    "###### We train for 30 epochs, as in the paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training...')\n",
    "\n",
    "for epoch in range(30):\n",
    "    print(\"Epoch {}\".format(epoch), flush=True)\n",
    "    train()\n",
    "    \n",
    "acc = test()\n",
    "print(\"Test accuracy: {:06.4f}\".format(acc), flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
